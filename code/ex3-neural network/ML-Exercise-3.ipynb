{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    " # 机器学习练习3-多类分类\n",
    "\n",
    "使用python语言完成作业\n",
    "\n",
    "代码修改并注释：Changersh，Changersh@outlook.com"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1、多类分类"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 读入数据\n",
    "\n",
    "数据以 .mat 类型存储，python中使用 `lodamat` 读取，是scipy.io中的工具\n",
    ".mat 文件会以矩阵的格式保存"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "{'__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sun Oct 16 13:09:09 2011',\n '__version__': '1.0',\n '__globals__': [],\n 'X': array([[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]),\n 'y': array([[10],\n        [10],\n        [10],\n        ...,\n        [ 9],\n        [ 9],\n        [ 9]], dtype=uint8)}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'ex3data1.mat'\n",
    "data = loadmat(path)\n",
    "data\n",
    "# 注意，此数据原用于 matlab，为了避免 0 索引，就将y中是0的结果，使用 10 代替。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 可视化数据\n",
    "没有对应的matlab函数，放弃了"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 向量化逻辑回归"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3.1 向量化Cost函数\n",
    "首先是 z 形函数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "逻辑回归的代价函数：\n",
    "$$\n",
    "J(\\theta)= \\frac{1}{m}\\sum_{i=1}^m[-y^{(i)}*log(h_\\theta(x^{i})) - (1-y^{i})*log(1-h_\\theta(x^{i}))] + \\frac{\\lambda}{2m}\\sum_{j=1}^n \\theta_j^2\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# 使用正则化之后的函数，没有 for 循环\n",
    "def cost(theta, X, y, learningRate):\n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    first = np.multiply(-y, np.log(sigmoid(X * theta.T)))\n",
    "    second = np.multiply((1 - y), np.log(1 - sigmoid(X * theta.T)))\n",
    "    reg = (learningRate / (2 * len(X))) * np.sum(np.power(theta[:,1:theta.shape[1]], 2))\n",
    "    return np.sum(first - second) / len(X) + reg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.3.2 向量化梯度函数gradient\n",
    "\n",
    "lam就是上面式子中的λ，是正则化参数，不能太大，否则会导致拟合效果很差。\n",
    "我们也要写出更新参数 θ 的函数，并且不用给出 学习速率α，因为我们后面使用第一题使用过的高级的方法，会自动给出学习速率\n",
    "$$\n",
    "Repeat \\ until \\ convergence \\{ \\\\\n",
    "\\theta_0 := \\theta_0 - \\alpha \\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)}) -y^{(i)})x_0^{(i)}\n",
    "\\\\\n",
    "\\theta_j := \\theta_j - \\alpha [\\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)}) -y^{(i)})x_j^{(i)} + \\frac{\\lambda}{m}\\theta_j]\n",
    "\\\\\n",
    "\\}\n",
    "$$\n",
    "\n",
    "后面一项可以化简\n",
    "$$\n",
    "\\theta_j := \\theta_j(1-\\alpha \\frac{\\lambda}{m}) - \\alpha \\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)}) -y^{(i)})x_j^{(i)}\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用 for 循环的梯度函数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def gradient_with_loop(theta, X, y, lam):\n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "\n",
    "    parameters = X.shape[1]\n",
    "    grad = np.zeros(parameters) # 存储梯度\n",
    "\n",
    "    error = sigmoid(X * theta.T) - y # 这一项跟theta没关系，预处理出来\n",
    "    for i in range(parameters):\n",
    "        tmp = np.sum(np.multiply(error, X[:, i])) / X.shape[0]\n",
    "        if i == 0:\n",
    "            grad[i] = tmp\n",
    "        else:\n",
    "            grad[i] = tmp + (lam * theta[:, i]) / X.shape[0]\n",
    "\n",
    "    return grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "向量化的梯度函数\n",
    "$$\n",
    "Repeat \\ until \\ convergence \\{ \\\\\n",
    "\\theta_0 := \\theta_0 - \\alpha \\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)}) -y^{(i)})x_0^{(i)}\n",
    "\\\\\n",
    "\\theta_j := \\theta_j - \\alpha [\\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)}) -y^{(i)})x_j^{(i)} + \\frac{\\lambda}{m}\\theta_j]\n",
    "\\\\\n",
    "\\}\n",
    "$$\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def gradient(theta, X, y, lam):\n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "\n",
    "    parameters = int(theta.ravel().shape[1])\n",
    "\n",
    "    error = sigmoid(X * theta.T) - y # 这一项跟theta没关系，预处理出来\n",
    "\n",
    "    grad = ((X.T * error) / X.shape[0]).T + ((lam / X.shape[0]) * theta)\n",
    "    grad[0, 0] = np.sum(np.multiply(error, X[:,0])) / X.shape[0]\n",
    "\n",
    "    return np.array(grad).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.4 One-vs-All分类\n",
    "\n",
    "我们有十个可能的类，逻辑回归只能在两个类之间分类。多类分类的策略就是分为 是i 和 不是i 两种，最后逐个套用分类器，比较概率。\n",
    "\n",
    "这样的话，循环进行分类，最后比较即可"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "# fmin_tnc 拟牛顿法用于最小优化问题\n",
    "def one_vs_all(X, y, num_labels, lam):\n",
    "    rows = X.shape[0]\n",
    "    params = X.shape[1]\n",
    "\n",
    "    # k * (n+1) k个分类器中，每个分类器的参数 theta\n",
    "    all_theta = np.zeros((num_labels, params + 1))\n",
    "\n",
    "    # 在 0 位置插入长度是 rows 的 1 ，以 axis=1（列）的形式\n",
    "    X = np.insert(X, 0, values=np.ones(rows), axis=1)\n",
    "\n",
    "    # 切记循环从 1 开始，0被映射为 10 了\n",
    "    for i in range(1, num_labels + 1):\n",
    "        theta = np.zeros(params + 1)\n",
    "        y_i = np.array([1 if label == i else 0 for label in y])\n",
    "        y_i = np.reshape(y_i, (rows, 1))\n",
    "\n",
    "        # 最小化函数求 theta\n",
    "        # x0是要优化的变量的初始值\n",
    "        # TNC是优化方法，截断牛顿法\n",
    "        # jac是梯度函数\n",
    "        fmin = minimize(fun=cost, x0=theta, args=(X, y_i, lam), method='TNC', jac=gradient)\n",
    "\n",
    "        all_theta[i-1, :] = fmin.x\n",
    "\n",
    "    return all_theta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "初始化各种向量，注意维度"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "((5000, 401), (5000, 1), (401,), (10, 401))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = data['X'].shape[0]\n",
    "params = data['X'].shape[1]\n",
    "\n",
    "all_theta = np.zeros((10, params + 1))\n",
    "\n",
    "X = np.insert(data['X'], 0, values=np.ones(rows), axis=1)\n",
    "\n",
    "theta = np.zeros(params + 1)\n",
    "\n",
    "y_0 = np.array([1 if label == 0 else 0 for label in data['y']])\n",
    "y_0 = np.reshape(y_0, (rows, 1))\n",
    "\n",
    "X.shape, y_0.shape, theta.shape, all_theta.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data['y'])#看下有几类标签"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "确保训练函数正确运行，得到合理的输出"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_4100\\2185741287.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mall_theta\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mone_vs_all\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'X'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'y'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mall_theta\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_4100\\2521882085.py\u001B[0m in \u001B[0;36mone_vs_all\u001B[1;34m(X, y, num_labels, lam)\u001B[0m\n\u001B[0;32m     21\u001B[0m         \u001B[1;31m# TNC是优化方法，截断牛顿法\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m         \u001B[1;31m# jac是梯度函数\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 23\u001B[1;33m         \u001B[0mfmin\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mminimize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfun\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcost\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx0\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtheta\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_i\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlam\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'TNC'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mjac\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mgradient\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     24\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m         \u001B[0mall_theta\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfmin\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\SoftDownload\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001B[0m in \u001B[0;36mminimize\u001B[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001B[0m\n\u001B[0;32m    700\u001B[0m                                callback=callback, **options)\n\u001B[0;32m    701\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mmeth\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'tnc'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 702\u001B[1;33m         res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001B[0m\u001B[0;32m    703\u001B[0m                             **options)\n\u001B[0;32m    704\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mmeth\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'cobyla'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\SoftDownload\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_tnc.py\u001B[0m in \u001B[0;36m_minimize_tnc\u001B[1;34m(fun, x0, args, jac, bounds, eps, scale, offset, mesg_num, maxCGit, maxiter, eta, stepmx, accuracy, minfev, ftol, xtol, gtol, rescale, disp, callback, finite_diff_rel_step, maxfun, **unknown_options)\u001B[0m\n\u001B[0;32m    422\u001B[0m             \u001B[0mmaxfun\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    423\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 424\u001B[1;33m     rc, nf, nit, x, funv, jacv = moduleTNC.tnc_minimize(\n\u001B[0m\u001B[0;32m    425\u001B[0m         \u001B[0mfunc_and_grad\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlow\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mup\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscale\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    426\u001B[0m         \u001B[0moffset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmessages\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmaxCGit\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmaxfun\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m_moduleTNC.pyx\u001B[0m in \u001B[0;36m_moduleTNC.tnc_minimize\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_moduleTNC.pyx\u001B[0m in \u001B[0;36m_moduleTNC.function\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mD:\\SoftDownload\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001B[0m in \u001B[0;36mfun_and_grad\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    284\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_update_x_impl\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    285\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_update_fun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 286\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_update_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    287\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mg\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    288\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\SoftDownload\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001B[0m in \u001B[0;36m_update_grad\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    254\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_update_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    255\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mg_updated\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 256\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_update_grad_impl\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    257\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mg_updated\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    258\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\SoftDownload\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001B[0m in \u001B[0;36mupdate_grad\u001B[1;34m()\u001B[0m\n\u001B[0;32m    165\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    166\u001B[0m             \u001B[1;32mdef\u001B[0m \u001B[0mupdate_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 167\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgrad_wrapped\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    168\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    169\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mgrad\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mFD_METHODS\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\SoftDownload\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001B[0m in \u001B[0;36mgrad_wrapped\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m    162\u001B[0m             \u001B[1;32mdef\u001B[0m \u001B[0mgrad_wrapped\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    163\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mngev\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 164\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0matleast_1d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgrad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    165\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    166\u001B[0m             \u001B[1;32mdef\u001B[0m \u001B[0mupdate_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_4100\\1951440370.py\u001B[0m in \u001B[0;36mgradient\u001B[1;34m(theta, X, y, lam)\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[0mparameters\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtheta\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mravel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m     \u001B[0merror\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msigmoid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mtheta\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mT\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0my\u001B[0m \u001B[1;31m# 这一项跟theta没关系，预处理出来\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m     \u001B[0mgrad\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mT\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0merror\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mT\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlam\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mtheta\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\SoftDownload\\anaconda3\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py\u001B[0m in \u001B[0;36m__mul__\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m    216\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mother\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mN\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    217\u001B[0m             \u001B[1;31m# This promotes 1-D vectors to row vectors\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 218\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mN\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0masmatrix\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mother\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    219\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0misscalar\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mother\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mor\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mother\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'__rmul__'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    220\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mN\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mother\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mdot\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "all_theta = one_vs_all(data['X'], data['y'], 10, 1)\n",
    "all_theta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "验证正确性之后，使用训练完毕的分类器预测每个图象的标签。\n",
    "我们算每个类的概率，输出标签为概率最高的类\n",
    "\n",
    "预测函数$h_\\theta = g(\\theta^TX)$\n",
    "预测出的是 正确的概率"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict_all(X, all_theta):\n",
    "    rows = X.shape[0]\n",
    "    params = X.shape[1]\n",
    "    num_labels = all_theta.shape[0]\n",
    "\n",
    "    X = np.insert(X, 0, values=np.ones(rows), axis=1)\n",
    "    X = np.matrix(X)\n",
    "    all_theta = np.matrix(all_theta)\n",
    "\n",
    "    h = sigmoid(X * all_theta.T) # 5000*10 是每个例子中，是数字 i 的概率\n",
    "\n",
    "    # 获得 h 中最大元素的索引\n",
    "    h_argmax = np.argmax(h, axis=1)\n",
    "\n",
    "    h_argmax = h_argmax + 1\n",
    "\n",
    "    return h_argmax"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = predict_all(data['X'], all_theta)\n",
    "correct = [1 if a == b else 0 for (a, b) in zip(y_pred, data['y'])]\n",
    "accuracy = (sum(map(int, correct)) / float(len(correct)))\n",
    "print ('accuracy = {0}%'.format(accuracy * 100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2、前反馈传播-神经网络"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}